# ğŸš¢ Titanic Survival Prediction | Machine Learning Project

Predicting survival on the Titanic using powerful classification algorithms.

This project uses the famous **Titanic dataset** to build a machine learning model that predicts whether a passenger survived or not based on features like age, sex, ticket class, and more.

---

## ğŸ¯ Business Problem

The goal is to create a predictive model that determines which passengers are more likely to survive the Titanic disaster.

By analyzing passenger details such as:
- **Age**
- **Sex**
- **Ticket Class**
- **Siblings/Spouse aboard**
- **Parents/Children aboard**
- **Fare**
- **Embarked Port**

We can predict the **`Survived`** status (0 = No, 1 = Yes) using classification algorithms.

---

## ğŸ“Š Dataset Features

| Feature      | Description                                  |
|--------------|----------------------------------------------|
| `PassengerId`| Unique ID of each passenger                  |
| `Survived`   | Survival (0 = No, 1 = Yes)                   |
| `Pclass`     | Ticket class (1 = 1st, 2 = 2nd, 3 = 3rd)     |
| `Name`       | Name of the passenger                        |
| `Sex`        | Gender                                       |
| `Age`        | Age in years                                 |
| `SibSp`      | # of siblings/spouses aboard                 |
| `Parch`      | # of parents/children aboard                 |
| `Ticket`     | Ticket number                                |
| `Fare`       | Passenger fare                               |
| `Cabin`      | Cabin number                                 |
| `Embarked`   | Port of Embarkation (C = Cherbourg, Q = Queenstown, S = Southampton) |

---

## ğŸ§  Models Used

Implemented and evaluated the following models:

- âœ… Logistic Regression  
- âœ… K-Nearest Neighbors (KNN)  
- âœ… Support Vector Machine (SVM)  
- âœ… Decision Tree  
- âœ… Random Forest  
- âœ… XGBoost â­ï¸ (Best Model - 90% Accuracy)  
- âœ… AdaBoost  
- âœ… Gradient Boosting  
- âœ… Artificial Neural Network (ANN)

---

## ğŸ“ˆ Best Model: XGBoost

Achieved **~90% accuracy** using **XGBoost**, which performed the best after feature engineering and hyperparameter tuning.

---

## ğŸ“Œ Tech Stack

| Tool/Library    | Purpose                      |
|------------------|------------------------------|
| Python ğŸ        | Main language                |
| Pandas & NumPy ğŸ“Š| Data manipulation            |
| Matplotlib & Seaborn ğŸ“ˆ | Visualizations     |
| Scikit-learn âš™ï¸ | ML models + Evaluation       |
| XGBoost ğŸ’¥       | Gradient boosting classifier |
| TensorFlow/Keras ğŸ¤– | ANN Model (optional)     |


---

ğŸ“Š Evaluation Metrics
- Accuracy

- Precision

- Recall

- F1 Score

- Confusion Matrix

- ROC AUC Curve

---

Future Work
- âœ… Deploy as a web app using Streamlit or Flask

- âœ… Use GridSearchCV for hyperparameter tuning

- âœ… Create a REST API for real-time prediction

- âœ… Experiment with Deep Learning further

---

ğŸ™‹â€â™€ï¸ Author
ğŸ‘©â€ğŸ’» Developed by Yukti Nadhe
